{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb49344adfa785e154e7f5cd60643298c51ca819"
   },
   "source": [
    "### Metastatic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1e92489350fd6543d60b41cbde9c69f332eb23e"
   },
   "source": [
    "Welcome back. In this section we will create the Metastatic_model. This model will predict whether or not Metastatic cancer tissue is present in histopathologic image  patches.\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "We will use Kaggle's version of the PCam (PatchCamelyon) dataset. It's part of the [Histopathologic Cancer Detection competition](https://www.kaggle.com/c/histopathologic-cancer-detection) where the challenge is to identify metastatic tissue in histopathologic scans of lymph node sections. \n",
    "\n",
    "The dataset consists of 220,025 image patches of size 96x96 (130,908 Metastatic negative and 89,117 Metastatic positive). \n",
    "\n",
    "The images are in tiff  format. Many web browsers, including Chrome, don't support the tiff format. Thus the web app wil not be able to accept tiff images. Before training, we will convert these images to png format. This will ensure that the model will be trained on images of similar quality to what we expect a user to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(101)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(101)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7bbdd52c81188b8e9c528b88d9fd0da176bf4bc"
   },
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_SIZE = 96\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "SAMPLE_SIZE = 80000 # the number of images we use from each of the two classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25802a26e4afba8f6dc42754f7f61da4c8cfea5c"
   },
   "source": [
    "### What files are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "699bb899bde433ba20fb0d086fa0f33a0f61a250"
   },
   "outputs": [],
   "source": [
    "os.listdir('../input/histopathologic-cancer-detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c24d1662f8bd5fc4d8c57c29449990a3520cd96b"
   },
   "source": [
    "### Labels as per csv file\n",
    "\n",
    "0 = no met tissue<br>\n",
    "1 =   has met tissue. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a285343c286be191aa827ff9b836b67821176a5"
   },
   "source": [
    "### How many training images are in each folder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54461212efed65ac377369a468c80e7d708010f4"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(len(os.listdir('../input/histopathologic-cancer-detection/train')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b90854e07d495d9f945a0e40189fd32a0c32bff5"
   },
   "source": [
    "### Create a Dataframe containing all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9c9f40ffab35044641b0dc7d9b18609af1aa25e"
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('../input/histopathologic-cancer-detection/train_labels.csv')\n",
    "\n",
    "# removing this image because it caused a training error previously\n",
    "df_data = df_data[df_data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n",
    "\n",
    "# removing this image because it's black\n",
    "df_data = df_data[df_data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n",
    "\n",
    "\n",
    "print(df_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cfbd53b7f8ea1929952ffed6221b380012618e32"
   },
   "source": [
    "### Check the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e18560bf69d3dfc0c4772e7c79bb119fd2eb634b"
   },
   "outputs": [],
   "source": [
    "df_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6efe2e5de99c4bf92079b1a7d0b892d30fc9d518"
   },
   "source": [
    "### Display a random sample of train images  by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1c5143f227da4262eafce8cf0210a02c8072fb8e"
   },
   "outputs": [],
   "source": [
    "# source: https://www.kaggle.com/gpreda/honey-bee-subspecies-classification\n",
    "\n",
    "def draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n",
    "    \n",
    "    \"\"\"\n",
    "    Give a column in a dataframe,\n",
    "    this function takes a sample of each class and displays that\n",
    "    sample on one row. The sample size is the same as figure_cols which\n",
    "    is the number of columns in the figure.\n",
    "    Because this function takes a random sample, each time the function is run it\n",
    "    displays different images.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    categories = (df.groupby([col_name])[col_name].nunique()).index\n",
    "    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n",
    "                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n",
    "    # draw a number of images for each location\n",
    "    for i, cat in enumerate(categories):\n",
    "        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n",
    "        for j in range(0,figure_cols):\n",
    "            file=IMAGE_PATH + sample.iloc[j]['id'] + '.tif'\n",
    "            im=cv2.imread(file)\n",
    "            ax[i, j].imshow(im, resample=True, cmap='gray')\n",
    "            ax[i, j].set_title(cat, fontsize=16)  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd38bcfb5839975e4fee9e70b93d42c29c1b5d2e"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = '../input/histopathologic-cancer-detection/train/' \n",
    "\n",
    "draw_category_images('label',4, df_data, IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1da4226777aefe65b1bb3430208ea91ea7ca7d9a"
   },
   "source": [
    "### Create the Train and Val Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "547f9f571ee82e20b7647e16ed36de7550046032"
   },
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1150500d2772b7f36cdaa5aa5fd7f0fb4a72628"
   },
   "source": [
    "#### Balance the target distribution\n",
    "We will reduce the number of samples in class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "270fc18640b552ecc3cb0e1dd3036441db7a4a2b"
   },
   "outputs": [],
   "source": [
    "# take a random sample of class 0 with size equal to num samples in class 1\n",
    "df_0 = df_data[df_data['label'] == 0].sample(SAMPLE_SIZE, random_state = 101)\n",
    "# filter out class 1\n",
    "df_1 = df_data[df_data['label'] == 1].sample(SAMPLE_SIZE, random_state = 101)\n",
    "\n",
    "# concat the dataframes\n",
    "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "# shuffle\n",
    "df_data = shuffle(df_data)\n",
    "\n",
    "df_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a166dec3ef84c66ad9cd815b63fc1a753df2eb76"
   },
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15ba9792e6a370b7560330af15b3cfe21185c1cb"
   },
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "\n",
    "# stratify=y creates a balanced validation set.\n",
    "y = df_data['label']\n",
    "\n",
    "df_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7de70d915a5f1d2599725e00bdb3b9103d947883"
   },
   "outputs": [],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "392c0eea00be8e43a6e55438d1458650e842030b"
   },
   "outputs": [],
   "source": [
    "df_val['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba17dd34b75367fc61df6634d51dac94c3ab4951"
   },
   "source": [
    "### Create a Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ff8acc2e92a1b1b5002d6e1bf9a1180c3256f19d"
   },
   "outputs": [],
   "source": [
    "# Create a new directory\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create 2 folders inside 'base_dir':\n",
    "\n",
    "# train_dir\n",
    "    # a_no_met_tissue\n",
    "    # b_has_met_tissue\n",
    "\n",
    "# val_dir\n",
    "    # a_no_met_tissue\n",
    "    # b_has_met_tissue\n",
    "\n",
    "\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "no_met_tissue = os.path.join(train_dir, 'a_no_met_tissue')\n",
    "os.mkdir(no_met_tissue)\n",
    "has_met_tissue = os.path.join(train_dir, 'b_has_met_tissue')\n",
    "os.mkdir(has_met_tissue)\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "no_met_tissue = os.path.join(val_dir, 'a_no_met_tissue')\n",
    "os.mkdir(no_met_tissue)\n",
    "has_met_tissue = os.path.join(val_dir, 'b_has_met_tissue')\n",
    "os.mkdir(has_met_tissue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03ca5d4b8b027c2712d7096314d3a79ef829b23c"
   },
   "outputs": [],
   "source": [
    "# check that the folders have been created\n",
    "os.listdir('base_dir/train_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6a2e56340ba18f3b63c1b129fd995fecfadaa21d"
   },
   "source": [
    "### Transfer the images into the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e84c8a9642b030094b1888af3299063f883112a6"
   },
   "outputs": [],
   "source": [
    "# Set the id as the index in df_data\n",
    "df_data.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "afb8969a9ee75c13bddc808a4bcc326611baaaaf"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get a list of train and val images\n",
    "train_list = list(df_train['id'])\n",
    "val_list = list(df_val['id'])\n",
    "\n",
    "\n",
    "\n",
    "# Transfer the train images\n",
    "\n",
    "for image in train_list:\n",
    "    \n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname_tif = image + '.tif'\n",
    "    # get the label for a certain image\n",
    "    target = df_data.loc[image,'label']\n",
    "    \n",
    "    # these must match the folder names\n",
    "    if target == 0:\n",
    "        label = 'a_no_met_tissue'\n",
    "    if target == 1:\n",
    "        label = 'b_has_met_tissue'\n",
    "    \n",
    "    # source path to image\n",
    "    src = os.path.join('../input/histopathologic-cancer-detection/train', fname_tif)\n",
    "    # change the new file name to png\n",
    "    fname_png = image + '.png'\n",
    "    # destination path to image\n",
    "    dst = os.path.join(train_dir, label, fname_png)\n",
    "\n",
    "    \n",
    "    # read the file as an array\n",
    "    cv2_image = cv2.imread(src)\n",
    "    # save the image at the destination as a png file\n",
    "    cv2.imwrite(dst, cv2_image)\n",
    " \n",
    "\n",
    "\n",
    "# Transfer the val images\n",
    "\n",
    "for image in val_list:\n",
    "    \n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname_tif = image + '.tif'\n",
    "    # get the label for a certain image\n",
    "    target = df_data.loc[image,'label']\n",
    "    \n",
    "    # these must match the folder names\n",
    "    if target == 0:\n",
    "        label = 'a_no_met_tissue'\n",
    "    if target == 1:\n",
    "        label = 'b_has_met_tissue'\n",
    "    \n",
    "\n",
    "    # source path to image\n",
    "    src = os.path.join('../input/histopathologic-cancer-detection/train', fname_tif)\n",
    "    # change the new file name to png\n",
    "    fname_png = image + '.png'\n",
    "    # destination path to image\n",
    "    dst = os.path.join(val_dir, label, fname_png)\n",
    "\n",
    "    \n",
    "    # read the file as an array\n",
    "    cv2_image = cv2.imread(src)\n",
    "    # save the image at the destination as a png file\n",
    "    cv2.imwrite(dst, cv2_image)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71532bfc32608289b1f773ffdbc8a7cea1bfb94c"
   },
   "outputs": [],
   "source": [
    "# check how many train images we have in each folder\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/a_no_met_tissue')))\n",
    "print(len(os.listdir('base_dir/train_dir/b_has_met_tissue')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "897e9df543bb65b47bb00019dc681125ca08ee5d"
   },
   "outputs": [],
   "source": [
    "# check how many val images we have in each folder\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/a_no_met_tissue')))\n",
    "print(len(os.listdir('base_dir/val_dir/b_has_met_tissue')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef780ac9a9fc89b4ff4f042593eb68992f354a1d"
   },
   "outputs": [],
   "source": [
    "# End of Data Preparation\n",
    "### ================================================================================== ###\n",
    "# Start of Model Building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f8dce940ee8a7a42aacb062e4c6b5a4a54dba58f"
   },
   "source": [
    "### Set Up the Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef4fe7be09f11ff4badfd22d5fd5e03f8521ed58"
   },
   "outputs": [],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "valid_path = 'base_dir/val_dir'\n",
    "test_path = '../input/test'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68fbd9d5fbb80859a82f94a12e335ce05a93bd51"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=train_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "test_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79da4d0a66a90cffe40580a596dd4d0e2bc45a9b"
   },
   "source": [
    "### Create the Model ArchitectureÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "b9835ea0fd0bca54138904895c39d38227a70c22"
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-5min-0-8253-lb\n",
    "\n",
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 32\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.3\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "75cfc4fcb8dd3408d1c4fcf8cd85e0e2f5b611d7"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9de9715f49a63b55775b10abd2f461b395e23b5d"
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "227d84a4f44c0b7256855c06ba04dabd58d89d84"
   },
   "outputs": [],
   "source": [
    "# Get the labels that are associated with each index\n",
    "print(val_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a746769db61563f226288eba9aa8a6584b9e8e0b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=20, verbose=1,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa15a8afda3593973726e9087cbd98073041c908"
   },
   "source": [
    "### Evaluate the model using the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70104420ec7f400cd06203f875dbeba30f4d8a96"
   },
   "outputs": [],
   "source": [
    "# get the metric names so we can use evaulate_generator\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "428bdf5b24ff8cef35012205c3f2eb37006fc9e9"
   },
   "outputs": [],
   "source": [
    "# Here the best epoch will be used.\n",
    "\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_acc = \\\n",
    "model.evaluate_generator(test_gen, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_acc:', val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93556c9e4b6a188cf9cb67a6519c9bc365c60caf"
   },
   "source": [
    "### Plot the Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "385da8ba94a1079d17909790716b295fc2737584"
   },
   "outputs": [],
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5636e76f23202dd1f2a27ace25e15e09619a5e4e"
   },
   "source": [
    "### Make a prediction on the val set\n",
    "We need these predictions to calculate the AUC score, print the Confusion Matrix and calculate the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "652d9d6aa51dc1818d1c5171212d10e141ad7de9"
   },
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "predictions = model.predict_generator(test_gen, steps=len(df_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "edf1866df4638ded26de2e0e3d2ba0f5e00e1ace"
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6bbf4f095fe5412561924c09c96d8dc2ea4adfc0"
   },
   "source": [
    "**A note on Keras class index values**\n",
    "\n",
    "Keras assigns it's own index value (here 0 and 1) to the classes. It infers the classes based on the folder structure.\n",
    "Important: These index values may not match the index values we were given in the train_labels.csv file.\n",
    "\n",
    "I've used 'a' and 'b' folder name pre-fixes to get keras to assign index values to match what was in the train_labels.csv file - I guessed that keras is assigning the index value based on folder name alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc71f69944e7db83329417c5265a5bc31f9c4fc3"
   },
   "outputs": [],
   "source": [
    "# This is how to check what index keras has internally assigned to each class. \n",
    "test_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a6709d73969f7fd597128223b110be077f84edb"
   },
   "outputs": [],
   "source": [
    "# Put the predictions into a dataframe.\n",
    "# The columns need to be oredered to match the output of the previous cell\n",
    "\n",
    "df_preds = pd.DataFrame(predictions, columns=['no_met_tissue', 'has_met_tissue'])\n",
    "\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0954d61a4ef8bc056452b3bbad9456d45c00bed1"
   },
   "outputs": [],
   "source": [
    "# Get the true labels\n",
    "y_true = test_gen.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['has_met_tissue']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f07c814d213e814cdac4e3d05d0a8db847fbfe28"
   },
   "source": [
    "### What is the AUC Score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b7b7a56c6fa47cc40764d0c06d64860580cbea1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d8404e8e6b6008c8989b8184700ec5562b99366"
   },
   "source": [
    "### Create a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "91f570e8e5f07126e5361bbf92929d786e853a09"
   },
   "outputs": [],
   "source": [
    "# Source: Scikit Learn website\n",
    "# http://scikit-learn.org/stable/auto_examples/\n",
    "# model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-\n",
    "# selection-plot-confusion-matrix-py\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c20bc358dc753020d5a560dc56f2350c7f40a4f9"
   },
   "outputs": [],
   "source": [
    "# Get the labels of the test images.\n",
    "\n",
    "test_labels = test_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a537724473df19c74bb1bf6928f531dd0fcfdb3"
   },
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0bb4323e931ff53081994bbf58e82b1ec93ab327"
   },
   "outputs": [],
   "source": [
    "# argmax returns the index of the max value in a row\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec2058223eb30485898a12c0e904bb170c0aa884"
   },
   "outputs": [],
   "source": [
    "# Print the label associated with each class\n",
    "test_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba26c7e718df937a18aa2035c4ba883252e44c79"
   },
   "outputs": [],
   "source": [
    "# Define the labels of the class indices. These need to match the \n",
    "# order shown above.\n",
    "cm_plot_labels = ['no_met_tissue', 'has_met_tissue']\n",
    "\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2576c1144cfe93d66f3197396990f3e43addd499"
   },
   "source": [
    "### Create a Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91dcace7eb99aca310774b7a3a55535c9127ce55"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a classification report\n",
    "\n",
    "# For this to work we need y_pred as binary labels not as probabilities\n",
    "y_pred_binary = predictions.argmax(axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred_binary, target_names=cm_plot_labels)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "36880545abb112946ebe48242d5da6c8517cf61b"
   },
   "source": [
    "**Recall **= Given a class, will the classifier be able to detect it?<br>\n",
    "**Precision **= Given a class prediction from a classifier, how likely is it to be correct?<br>\n",
    "**F1 Score** = The harmonic mean of the recall and precision. Essentially, it punishes extreme values.\n",
    "\n",
    "From the confusion matrix and classification report we see that our model is equally good at detecting both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b0b4f6065e0ba97d9170cc6d9e23ae3d064a73e"
   },
   "source": [
    "### Convert the model to from Keras to Tensorflowjs\n",
    "This conversion needs to be done so that the model can be loaded into the web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1510fc5dedb309e4b03c6cbee3acf27f55739ecc"
   },
   "outputs": [],
   "source": [
    "# Delete the base_dir directory we created to free up disk space to download tensorflowjs\n",
    "# and to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree('base_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "28dd1e74473a0523885e50e8d17fd7d50036d9df"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d565698d4fd2e7479bb0331bf9c9c73fd97fb64d"
   },
   "outputs": [],
   "source": [
    "# Use the command line conversion tool to convert the model\n",
    "\n",
    "!tensorflowjs_converter --input_format keras model.h5 tfjs_model_2/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "daf2016cea165e5aad1ad28f92a81f0ca08d800f"
   },
   "source": [
    "### Lessons learned while building the web app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c9ae43bfacf8c8a579484705e9dce379daf1e54a"
   },
   "source": [
    "**1.**<br>\n",
    "Most web browsers don't support the tiff image format, which is contained in the dataset. While preprocessing the same for our web application we converted the images to .png format such that the model is trained with data i.e. similar to the expected input..\n",
    "\n",
    "**2.**<br>\n",
    "Because Tensorflowjs is a new technology, web apps bulit using it may not work in some browsers. The user will see a message saying the \"Ai is loading...\" but that message will never go away because the app is actually frozen. It's better to advise users to use the latest version of Chrome.\n",
    "\n",
    "**3.**<br>\n",
    "The web app for this project uses the Javascript language for the most part. We also used Javascript to feed the images to the model. The challenge is that Javascript is very fast whereas the model isn't fast enough to keep up. This difference in speed can lead to incorrect predictions. We used async/await to fix this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb92189bf34d85d3e5088803fc170297456da902"
   },
   "source": [
    "\n",
    "### Resources\n",
    "\n",
    "\n",
    "1. Gabriel Preda, Honey Bee Subspecies Classification <br>\n",
    "https://www.kaggle.com/gpreda/honey-bee-subspecies-classification<br>\n",
    "\n",
    "2. Beluga, Black and White CNN<br>\n",
    "https://www.kaggle.com/gaborfodor/black-white-cnn-lb-0-77\n",
    "\n",
    "3.  Francesco Marazzi, Baseline Keras CNN<br>\n",
    "https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-5min-0-8253-lb\n",
    "\n",
    "4. YouTube tutorial by deeplizard on how to use Tensorflowjs<br>\n",
    "https://www.youtube.com/watch?v=HEQDRWMK6yY\n",
    "\n",
    "5. Tutorial by jenkov.com explaining the HTML5 File API<br>\n",
    "http://tutorials.jenkov.com/html5/file-api.html\n",
    "\n",
    "6. Blog post by Anton Lavrenov on how to handle async/await<br>\n",
    "https://blog.lavrton.com/javascript-loops-how-to-handle-async-await-6252dd3c795\n",
    "\n",
    "7. jQuery tutorial by W3Schools<br>\n",
    "https://www.w3schools.com/jquery/default.asp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b789103dec6faf61148e291c59f9c7f13d1344a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
